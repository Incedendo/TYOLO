{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Robotics_videomods_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qdFM7wjHtQZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import cv2\n",
        "import imutils\n",
        "from imutils.video import FPS\n",
        "from imutils.video import VideoStream\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Individual Blocks"
      ],
      "metadata": {
        "id": "enoFjy-tmiE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('/content/drive/MyDrive/TYOLO/yolov5', 'custom', path='/content/drive/MyDrive/TYOLO/yolov5/runs/train/exp16/weights/best.pt', source='local')"
      ],
      "metadata": {
        "id": "3YHu7rS7NGy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_distance(y1,y2) :\n",
        "  # diag = ((x1-x2)**2 + (y1-y2)**2)**(1/2)\n",
        "  X = 1.0688\n",
        "  f = 12\n",
        "  real_h = 1067\n",
        "  image_h = 480\n",
        "  obj_h = abs(y1-y2)\n",
        "  Sensor_h = 5.29 \n",
        "  D = (f * image_h * real_h) / (obj_h * Sensor_h)\n",
        "  return str(int(D/1000))"
      ],
      "metadata": {
        "id": "25QpuU8UkX_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vs = cv2.VideoCapture('/content/drive/MyDrive/TYOLO/Lara_Test.mp4')\n",
        "writer = None\n",
        "(W, H) = (None, None)\n",
        "# try to determine the total number of frames in the video file\n",
        "try:\n",
        "\tprop = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() \\\n",
        "\t\telse cv2.CAP_PROP_FRAME_COUNT\n",
        "\ttotal = int(vs.get(prop))\n",
        "\tprint(\"[INFO] {} total frames in video\".format(total))\n",
        "# an error occurred while trying to determine the total\n",
        "# number of frames in the video file\n",
        "except:\n",
        "\tprint(\"[INFO] could not determine # of frames in video\")\n",
        "\tprint(\"[INFO] no approx. completion time can be provided\")\n",
        "\ttotal = -1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDM-f1nnH7Fq",
        "outputId": "33cf07d7-ddee-48f6-9342-bba89543c529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] 540 total frames in video\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "while True:\n",
        "  # read the next frame from the file\n",
        "  (grabbed, frame) = vs.read()\n",
        "  if count==0 :\n",
        "    f = frame\n",
        "    count+=1\n",
        "  # if the frame was not grabbed, then we have reached the end\n",
        "  # of the stream\n",
        "  if not grabbed:\n",
        "    break\n",
        "  # if the frame dimensions are empty, grab them\n",
        "  if W is None or H is None:\n",
        "    (H, W) = frame.shape[:2]\n",
        "\n",
        "  ###################################################################\n",
        "  # Passing the top 40% frames to the model to improve performance ##\n",
        "\n",
        "  optimal_frame = np.zeros((frame.shape[0], frame.shape[1],3),dtype=float)\n",
        "  # print(type(frame[0:int(frame.shape[0]*0.4)][:]))\n",
        "  optimal_frame[0:int(frame.shape[0]*0.4)][:] = frame[0:int(frame.shape[0]*0.4)][:]\n",
        "  start = time.time()\n",
        "  layerOutputs = model(optimal_frame)\n",
        "  # print(layerOutputs)\n",
        "  # layerOutputs.print()\n",
        "  # print(layerOutputs.xyxy[0])\n",
        "  ####################################################################\n",
        "\n",
        "  if len(layerOutputs.xyxy[0]) > 0 :\n",
        "    for i in layerOutputs.xyxy[0] :\n",
        "      try:\n",
        "        x1 = i[0]\n",
        "        y1 = i[1]\n",
        "        x2 = i[2]\n",
        "        y2 = i[3]\n",
        "        label = i[5]\n",
        "        if(label == 0) :\n",
        "          label_text = 'go '\n",
        "        else :\n",
        "          label_text = 'stop '\n",
        "        dist = calculate_distance(y1,y2) ## distance calculation using heigth of bounding box\n",
        "        text =  label_text + dist + ' m'\n",
        "        print(text)\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (255,255,255), 2)\n",
        "        cv2.putText(frame,text, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2) #Put a label over box.\n",
        "        # print(dist)\n",
        "        # cv2.putText(frame,, (10, 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2)\n",
        "      except:\n",
        "        continue\n",
        "  end = time.time()\n",
        "\n",
        "\n",
        "  if writer is None:\n",
        "    # initialize our video writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "    writer = cv2.VideoWriter(\"/content/drive/MyDrive/TYOLO/Test3.mp4\", fourcc, 30,\n",
        "      (frame.shape[1], frame.shape[0]), True)\n",
        "    # some information on processing single frame\n",
        "    if total > 0:\n",
        "      elap = (end - start)\n",
        "      print(\"[INFO] single frame took {:.4f} seconds\".format(elap))\n",
        "      print(\"[INFO] estimated total time to finish: {:.4f}\".format(\n",
        "        elap * total))\n",
        "  # write the output frame to the disk\n",
        "  writer.write(frame)\n",
        "  # release file pointers\n",
        "print(\"[INFO] cleaning up...\")\n",
        "writer.release()\n",
        "vs.release()"
      ],
      "metadata": {
        "id": "jAhdMGkqIDNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combined Function"
      ],
      "metadata": {
        "id": "sko4KXk0mqQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_video(yolo_dir_path, yolo_weight_path, input_video_path, output_video_path) :\n",
        "  print(\"Loading Model\")\n",
        "  try :\n",
        "    model = torch.hub.load(yolo_dir_path, 'custom', path=yolo_weight_path, source='local')\n",
        "    print(\"Model Successfully loaded\")\n",
        "  except :\n",
        "    print(\"Falied to load model\")\n",
        "\n",
        "  ######## Video Detection Part ###################\n",
        "  vs = cv2.VideoCapture(input_video_path)\n",
        "  writer = None\n",
        "  (W, H) = (None, None)\n",
        "  # try to determine the total number of frames in the video file\n",
        "  try:\n",
        "    prop = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() \\\n",
        "      else cv2.CAP_PROP_FRAME_COUNT\n",
        "    total = int(vs.get(prop))\n",
        "    print(\"[INFO] {} total frames in video\".format(total))\n",
        "  # an error occurred while trying to determine the total\n",
        "  # number of frames in the video file\n",
        "  except:\n",
        "    print(\"[INFO] could not determine # of frames in video\")\n",
        "    print(\"[INFO] no approx. completion time can be provided\")\n",
        "    total = -1\n",
        "\n",
        "\n",
        "  count = 0\n",
        "  while True:\n",
        "    # read the next frame from the file\n",
        "    (grabbed, frame) = vs.read()\n",
        "    if count==0 :\n",
        "      f = frame\n",
        "      count+=1\n",
        "    # if the frame was not grabbed, then we have reached the end\n",
        "    # of the stream\n",
        "    if not grabbed:\n",
        "      break\n",
        "    # if the frame dimensions are empty, grab them\n",
        "    if W is None or H is None:\n",
        "      (H, W) = frame.shape[:2]\n",
        "\n",
        "    ###################################################################\n",
        "    # Passing the top 40% frames to the model to improve performance ##  \n",
        "\n",
        "    optimal_frame = np.zeros((frame.shape[0], frame.shape[1],3),dtype=float)\n",
        "    # print(type(frame[0:int(frame.shape[0]*0.4)][:]))\n",
        "    optimal_frame[0:int(frame.shape[0]*0.4)][:] = frame[0:int(frame.shape[0]*0.4)][:]\n",
        "    start = time.time()\n",
        "    layerOutputs = model(optimal_frame)\n",
        "    # print(layerOutputs)\n",
        "    # layerOutputs.print()\n",
        "    # print(layerOutputs.xyxy[0])\n",
        "    ####################################################################\n",
        "    \n",
        "    if len(layerOutputs.xyxy[0]) > 0 :\n",
        "      for i in layerOutputs.xyxy[0] :\n",
        "        try:\n",
        "          x1 = i[0]\n",
        "          y1 = i[1]\n",
        "          x2 = i[2]\n",
        "          y2 = i[3]\n",
        "          label = i[5]\n",
        "          if(label == 0) :\n",
        "            label_text = 'go '\n",
        "          else :\n",
        "            label_text = 'stop '\n",
        "          dist = calculate_distance(y1,y2)  ## distance calculation\n",
        "          text =  label_text + dist + ' m'\n",
        "          print(text)\n",
        "          cv2.rectangle(frame, (x1, y1), (x2, y2), (255,255,255), 2)\n",
        "          cv2.putText(frame,text, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2) #Put a label over box.\n",
        "          # print(dist)\n",
        "          # cv2.putText(frame,, (10, 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2)\n",
        "        except:\n",
        "          continue\n",
        "    end = time.time()\n",
        "\n",
        "\n",
        "    if writer is None:\n",
        "      # initialize our video writer\n",
        "      fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "      writer = cv2.VideoWriter(output_video_path, fourcc, 30,\n",
        "        (frame.shape[1], frame.shape[0]), True)\n",
        "      # some information on processing single frame\n",
        "      if total > 0:\n",
        "        elap = (end - start)\n",
        "        print(\"[INFO] single frame took {:.4f} seconds\".format(elap))\n",
        "        print(\"[INFO] estimated total time to finish: {:.4f}\".format(\n",
        "          elap * total))\n",
        "    # write the output frame to disk\n",
        "    writer.write(frame)\n",
        "    # release the file pointers\n",
        "  print(\"[INFO] cleaning up...\")\n",
        "  writer.release()\n",
        "  vs.release()"
      ],
      "metadata": {
        "id": "BU3tY011oOAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run for a Video"
      ],
      "metadata": {
        "id": "KEt9xrA1oX_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolov5_dir_path = \"/content/drive/MyDrive/TYOLO/yolov5\"\n",
        "custom_wt_path = \"/content/drive/MyDrive/TYOLO/yolov5/runs/train/exp16/weights/best.pt\"\n",
        "test_video_path = \"/content/drive/MyDrive/TYOLO/dataset/test_videos/Test4.mp4\"\n",
        "output_video_path = \"/content/drive/MyDrive/TYOLO/dataset/test_videos/Test4_result.mp4\""
      ],
      "metadata": {
        "id": "2oBZDdjgrgjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detect_video(yolov5_dir_path, custom_wt_path, test_video_path , output_video_path)"
      ],
      "metadata": {
        "id": "O3AZTtbuiseA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CDDYF154sDAC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}